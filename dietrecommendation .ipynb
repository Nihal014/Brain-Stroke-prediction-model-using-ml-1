{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "os.environ['OPENAI_API_KEY'] = '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' # apenai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\n",
      "     ------------------------------------ 806.7/806.7 KB 879.1 kB/s eta 0:00:00\n",
      "Collecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl (145 kB)\n",
      "     -------------------------------------- 145.3/145.3 KB 2.9 MB/s eta 0:00:00\n",
      "Collecting langchain-community<0.1,>=0.0.17\n",
      "  Downloading langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.25-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from langchain) (2.6.1)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-win_amd64.whl (365 kB)\n",
      "     ------------------------------------ 365.2/365.2 KB 597.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from langchain) (2.28.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83\n",
      "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "     -------------------------------------- 55.4/55.4 KB 980.7 kB/s eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from langchain) (1.23.5)\n",
      "Collecting langchain-core<0.2,>=0.1.16\n",
      "  Downloading langchain_core-0.1.21-py3-none-any.whl (238 kB)\n",
      "     ------------------------------------ 238.5/238.5 KB 665.6 kB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "     -------------------------------------- 76.4/76.4 KB 848.2 kB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "     -------------------------------------- 50.4/50.4 KB 638.0 kB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "     -------------------------------------- 49.4/49.4 KB 834.2 kB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2,>=0.1.16->langchain) (4.2.0)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.0/53.0 KB ? eta 0:00:00\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain) (3.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, SQLAlchemy, PyYAML, packaging, mypy-extensions, multidict, jsonpointer, frozenlist, async-timeout, yarl, typing-inspect, marshmallow, jsonpatch, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.25 aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.5 langchain-community-0.0.19 langchain-core-0.1.21 langsmith-0.0.87 marshmallow-3.20.2 multidict-6.0.5 mypy-extensions-1.0.0 packaging-23.2 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting openai\n",
      "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
      "     ------------------------------------ 226.1/226.1 KB 990.1 kB/s eta 0:00:00\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "     -------------------------------------- 78.3/78.3 KB 872.0 kB/s eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "     -------------------------------------- 85.5/85.5 KB 690.3 kB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "     -------------------------------------- 75.9/75.9 KB 323.3 kB/s eta 0:00:00\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "     ------------------------------------ 394.8/394.8 KB 983.5 kB/s eta 0:00:00\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions<5,>=4.7\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 76.9/76.9 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 KB 1.0 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.16.2\n",
      "  Downloading pydantic_core-2.16.2-cp310-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\muham\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, h11, exceptiongroup, distro, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.2.0 distro-1.9.0 exceptiongroup-1.2.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.11.1 pydantic-2.6.1 pydantic-core-2.16.2 sniffio-1.3.0 tqdm-4.66.1 typing-extensions-4.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_resto = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_resto = PromptTemplate(\n",
    "    input_variables=['age', 'gender', 'weight', 'height', 'veg_or_nonveg', 'disease', 'region', 'allergics', 'foodtype'],\n",
    "    template=\"Diet Recommendation System:\\n\"\n",
    "             \"I want you to recommend 6 restaurants names, 6 breakfast names, 5 dinner names, and 6 workout names, \"\n",
    "             \"based on the following criteria:\\n\"\n",
    "             \"Person age: {age}\\n\"\n",
    "             \"Person gender: {gender}\\n\"\n",
    "             \"Person weight: {weight}\\n\"\n",
    "             \"Person height: {height}\\n\"\n",
    "             \"Person veg_or_nonveg: {veg_or_nonveg}\\n\"\n",
    "             \"Person generic disease: {disease}\\n\"\n",
    "             \"Person region: {region}\\n\"\n",
    "             \"Person allergics: {allergics}\\n\"\n",
    "             \"Person foodtype: {foodtype}.\"\n",
    ")\n",
    "\n",
    "chain_resto = LLMChain(llm=llm_resto, prompt=prompt_template_resto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain_resto = LLMChain(llm=llm_resto, prompt=prompt_template_resto)\n",
    "# Define the input dictionary\n",
    "input_data = {\n",
    "    'age': 60,\n",
    "    'gender': 'male',\n",
    "    'weight': 120,\n",
    "    'height': 5,\n",
    "    'veg_or_nonveg': 'veg',\n",
    "    'disease': 'aneamia',\n",
    "    'region': 'Pakistan',\n",
    "    'allergics': 'Latex Allergy',\n",
    "    'foodtype': 'Fruits'\n",
    "}\n",
    "\n",
    "results = chain_resto.run(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRestaurants:\\n1. Veggie Delight\\n2. Green Garden\\n3. Fresh and Fit\\n4. The Herbivore\\n5. Nourish Kitchen\\n6. Veggie Haven\\n\\nBreakfast:\\n1. Fruit and Yogurt Parfait\\n2. Veggie Omelette\\n3. Avocado Toast\\n4. Quinoa Breakfast Bowl\\n5. Smoothie Bowl\\n6. Veggie Frittata\\n\\nDinner:\\n1. Lentil Curry with Brown Rice\\n2. Grilled Vegetable Kabobs\\n3. Spinach and Chickpea Salad\\n4. Vegetable Stir Fry\\n5. Roasted Sweet Potato and Black Bean Tacos\\n6. Zucchini Noodle Pad Thai\\n\\nWorkouts:\\n1. Low Impact Yoga\\n2. Pilates for Seniors\\n3. Walking or Jogging in the Park\\n4. Resistance Band Training\\n5. Swimming laps\\n6. Gentle Stretching and Mobility Exercises'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Restaurants:\n",
      "1. Veggie Delight\n",
      "2. Green Garden\n",
      "3. Fresh and Fit\n",
      "4. The Herbivore\n",
      "5. Nourish Kitchen\n",
      "6. Veggie Haven\n",
      "\n",
      "Breakfast:\n",
      "1. Fruit and Yogurt Parfait\n",
      "2. Veggie Omelette\n",
      "3. Avocado Toast\n",
      "4. Quinoa Breakfast Bowl\n",
      "5. Smoothie Bowl\n",
      "6. Veggie Frittata\n",
      "\n",
      "Dinner:\n",
      "1. Lentil Curry with Brown Rice\n",
      "2. Grilled Vegetable Kabobs\n",
      "3. Spinach and Chickpea Salad\n",
      "4. Vegetable Stir Fry\n",
      "5. Roasted Sweet Potato and Black Bean Tacos\n",
      "6. Zucchini Noodle Pad Thai\n",
      "\n",
      "Workouts:\n",
      "1. Low Impact Yoga\n",
      "2. Pilates for Seniors\n",
      "3. Walking or Jogging in the Park\n",
      "4. Resistance Band Training\n",
      "5. Swimming laps\n",
      "6. Gentle Stretching and Mobility Exercises\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Extracting the different recommendations using regular expressions\n",
    "restaurant_names = re.findall(r'Restaurants:(.*?)Breakfast:', results, re.DOTALL)\n",
    "breakfast_names = re.findall(r'Breakfast:(.*?)Dinner:', results, re.DOTALL)\n",
    "dinner_names = re.findall(r'Dinner:(.*?)Workouts:', results, re.DOTALL)\n",
    "workout_names = re.findall(r'Workouts:(.*?)$', results, re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the extracted lists\n",
    "restaurant_names = [name.strip() for name in restaurant_names[0].strip().split('\\n') if name.strip()] if restaurant_names else []\n",
    "breakfast_names = [name.strip() for name in breakfast_names[0].strip().split('\\n') if name.strip()] if breakfast_names else []\n",
    "dinner_names = [name.strip() for name in dinner_names[0].strip().split('\\n') if name.strip()] if dinner_names else []\n",
    "workout_names = [name.strip() for name in workout_names[0].strip().split('\\n') if name.strip()] if workout_names else []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Restaurants: ['1. Veggie Delight', '2. Green Garden', '3. Fresh and Fit', '4. The Herbivore', '5. Nourish Kitchen', '6. Veggie Haven']\n",
      "Recommended Breakfasts: ['1. Fruit and Yogurt Parfait', '2. Veggie Omelette', '3. Avocado Toast', '4. Quinoa Breakfast Bowl', '5. Smoothie Bowl', '6. Veggie Frittata']\n",
      "Recommended Dinners: ['1. Lentil Curry with Brown Rice', '2. Grilled Vegetable Kabobs', '3. Spinach and Chickpea Salad', '4. Vegetable Stir Fry', '5. Roasted Sweet Potato and Black Bean Tacos', '6. Zucchini Noodle Pad Thai']\n",
      "Recommended Workouts: ['1. Low Impact Yoga', '2. Pilates for Seniors', '3. Walking or Jogging in the Park', '4. Resistance Band Training', '5. Swimming laps', '6. Gentle Stretching and Mobility Exercises']\n"
     ]
    }
   ],
   "source": [
    "# Printing the recommendations separately\n",
    "print(\"Recommended Restaurants:\", restaurant_names)\n",
    "print(\"Recommended Breakfasts:\", breakfast_names)\n",
    "print(\"Recommended Dinners:\", dinner_names)\n",
    "print(\"Recommended Workouts:\", workout_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Low Impact Yoga',\n",
       " '2. Pilates for Seniors',\n",
       " '3. Walking or Jogging in the Park',\n",
       " '4. Resistance Band Training',\n",
       " '5. Swimming laps',\n",
       " '6. Gentle Stretching and Mobility Exercises']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workout_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
